<!-- This file is machine generated: DO NOT EDIT! -->

# Inputs and Readers <a class="md-anchor" id="AUTOGENERATED-inputs-and-readers"></a>

Note: Functions taking `Tensor` arguments can also take anything accepted by
[`tf.convert_to_tensor`](../../api_docs/python/framework.md#convert_to_tensor).

<!-- TOC-BEGIN This section is generated by neural network: DO NOT EDIT! -->
## Contents
### [Inputs and Readers](#AUTOGENERATED-inputs-and-readers)
* [Placeholders](#AUTOGENERATED-placeholders)
  * [`tf.placeholder(dtype, shape=None, name=None)`](#placeholder)
* [Readers](#AUTOGENERATED-readers)
  * [`class tf.ReaderBase`](#ReaderBase)
  * [`class tf.TextLineReader`](#TextLineReader)
  * [`class tf.WholeFileReader`](#WholeFileReader)
  * [`class tf.IdentityReader`](#IdentityReader)
  * [`class tf.TFRecordReader`](#TFRecordReader)
  * [`class tf.FixedLengthRecordReader`](#FixedLengthRecordReader)
* [Converting](#AUTOGENERATED-converting)
  * [`tf.decode_csv(records, record_defaults, field_delim=None, name=None)`](#decode_csv)
  * [`tf.decode_raw(bytes, out_type, little_endian=None, name=None)`](#decode_raw)
  * [Example protocol buffer](#AUTOGENERATED-example-protocol-buffer)
  * [`tf.parse_example(serialized, names=None, sparse_keys=None, sparse_types=None, dense_keys=None, dense_types=None, dense_defaults=None, dense_shapes=None, name='ParseExample')`](#parse_example)
  * [`tf.parse_single_example(serialized, names=None, sparse_keys=None, sparse_types=None, dense_keys=None, dense_types=None, dense_defaults=None, dense_shapes=None, name='ParseSingleExample')`](#parse_single_example)
* [Queues](#AUTOGENERATED-queues)
  * [`class tf.QueueBase`](#QueueBase)
  * [`class tf.FIFOQueue`](#FIFOQueue)
  * [`class tf.RandomShuffleQueue`](#RandomShuffleQueue)
* [Dealing with the filesystem](#AUTOGENERATED-dealing-with-the-filesystem)
  * [`tf.matching_files(pattern, name=None)`](#matching_files)
  * [`tf.read_file(filename, name=None)`](#read_file)
* [Input pipeline](#AUTOGENERATED-input-pipeline)
  * [Beginning of an input pipeline](#AUTOGENERATED-beginning-of-an-input-pipeline)
  * [`tf.train.match_filenames_once(pattern, name=None)`](#match_filenames_once)
  * [`tf.train.limit_epochs(tensor, num_epochs=None, name=None)`](#limit_epochs)
  * [`tf.train.range_input_producer(limit, num_epochs=None, shuffle=True, seed=None, capacity=32, name=None)`](#range_input_producer)
  * [`tf.train.slice_input_producer(tensor_list, num_epochs=None, shuffle=True, seed=None, capacity=32, name=None)`](#slice_input_producer)
  * [`tf.train.string_input_producer(string_tensor, num_epochs=None, shuffle=True, seed=None, capacity=32, name=None)`](#string_input_producer)
  * [Batching at the end of an input pipeline](#AUTOGENERATED-batching-at-the-end-of-an-input-pipeline)
  * [`tf.train.batch(tensor_list, batch_size, num_threads=1, capacity=32, enqueue_many=False, shapes=None, name=None)`](#batch)
  * [`tf.train.batch_join(tensor_list_list, batch_size, capacity=32, enqueue_many=False, shapes=None, name=None)`](#batch_join)
  * [`tf.train.shuffle_batch(tensor_list, batch_size, capacity, min_after_dequeue, num_threads=1, seed=None, enqueue_many=False, shapes=None, name=None)`](#shuffle_batch)
  * [`tf.train.shuffle_batch_join(tensor_list_list, batch_size, capacity, min_after_dequeue, seed=None, enqueue_many=False, shapes=None, name=None)`](#shuffle_batch_join)


<!-- TOC-END This section was generated by neural network, THANKS FOR READING! -->

## Placeholders <a class="md-anchor" id="AUTOGENERATED-placeholders"></a>

TensorFlow provides a placeholder operation that must be fed with data
on execution.  For more info, see the section on [Feeding
data](../../how_tos/reading_data/index.md#feeding).

- - -

### `tf.placeholder(dtype, shape=None, name=None)` <a class="md-anchor" id="placeholder"></a>

Inserts a placeholder for a tensor that will be always fed.

**Important**: This tensor will produce an error if evaluated. Its value must
be fed using the `feed_dict` optional argument to `Session.run()`,
`Tensor.eval()`, or `Operation.run()`.

For example:

```python
x = tf.placeholder(float, shape=(1024, 1024))
y = tf.matmul(x, x)

with tf.Session() as sess:
  print sess.run(y)  # ERROR: will fail because x was not fed.

  rand_array = np.random.rand(1024, 1024)
  print sess.run(y, feed_dict={x: rand_array})  # Will succeed.
```

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`dtype`</b>: The type of elements in the tensor to be fed.
*  <b>`shape`</b>: The shape of the tensor to be fed (optional). If the shape is not
    specified, you can feed a tensor of any shape.
*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  A `Tensor` that may be used as a handle for feeding a value, but not
  evaluated directly.



## Readers <a class="md-anchor" id="AUTOGENERATED-readers"></a>

TensorFlow provides a set of Reader classes for reading data formats.
For more information on inputs and readers, see [Reading
data](../../how_tos/reading_data/index.md).

- - -

### `class tf.ReaderBase` <a class="md-anchor" id="ReaderBase"></a>

Base class for different Reader types, that produce a record every step.

Conceptually, Readers convert string 'work units' into records (key,
value pairs).  Typically the 'work units' are filenames and the
records are extracted from the contents of those files.  We want a
single record produced per step, but a work unit can correspond to
many records.

Therefore we introduce some decoupling using a queue.  The queue
contains the work units and the Reader dequeues from the queue when
it is asked to produce a record (via Read()) but it has finished the
last work unit.
- - -

#### `tf.ReaderBase.__init__(reader_ref, supports_serialize=False)` <a class="md-anchor" id="ReaderBase.__init__"></a>

Creates a new ReaderBase.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`reader_ref`</b>: The operation that implements the reader.
*  <b>`supports_serialize`</b>: True if the reader implementation can
    serialize its state.


- - -

#### `tf.ReaderBase.num_records_produced(name=None)` <a class="md-anchor" id="ReaderBase.num_records_produced"></a>

Returns the number of records this reader has produced.

This is the same as the number of Read executions that have
succeeded.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  An int64 Tensor.


- - -

#### `tf.ReaderBase.num_work_units_completed(name=None)` <a class="md-anchor" id="ReaderBase.num_work_units_completed"></a>

Returns the number of work units this reader has finished processing.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  An int64 Tensor.


- - -

#### `tf.ReaderBase.read(queue, name=None)` <a class="md-anchor" id="ReaderBase.read"></a>

Returns the next record (key, value pair) produced by a reader.

Will dequeue a work unit from queue if necessary (e.g. when the
Reader needs to start reading from a new file since it has
finished with the previous file).

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`queue`</b>: A Queue or a mutable string Tensor representing a handle
    to a Queue, with string work items.
*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  A tuple of Tensors (key, value).

*  <b>`key`</b>: A string scalar Tensor.
*  <b>`value`</b>: A string scalar Tensor.


- - -

#### `tf.ReaderBase.reader_ref` <a class="md-anchor" id="ReaderBase.reader_ref"></a>

Op that implements the reader.

- - -

#### `tf.ReaderBase.reset(name=None)` <a class="md-anchor" id="ReaderBase.reset"></a>

Restore a reader to its initial clean state.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  The created Operation.


- - -

#### `tf.ReaderBase.restore_state(state, name=None)` <a class="md-anchor" id="ReaderBase.restore_state"></a>

Restore a reader to a previously saved state.

Not all Readers support being restored, so this can produce an
Unimplemented error.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`state`</b>: A string Tensor.
    Result of a SerializeState of a Reader with matching type.
*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  The created Operation.


- - -

#### `tf.ReaderBase.serialize_state(name=None)` <a class="md-anchor" id="ReaderBase.serialize_state"></a>

Produce a string tensor that encodes the state of a reader.

Not all Readers support being serialized, so this can produce an
Unimplemented error.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  A string Tensor.


- - -

#### `tf.ReaderBase.supports_serialize` <a class="md-anchor" id="ReaderBase.supports_serialize"></a>

Whether the Reader implementation can serialize its state.


- - -

### `class tf.TextLineReader` <a class="md-anchor" id="TextLineReader"></a>

A Reader that outputs the lines of a file delimited by newlines.
返回一个文件的行
Newlines are stripped from the output.
See ReaderBase for supported methods.
- - -

#### `tf.TextLineReader.__init__(skip_header_lines=None, name=None)` <a class="md-anchor" id="TextLineReader.__init__"></a>

Create a TextLineReader.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`skip_header_lines`</b>: An optional int. Defaults to 0.  Number of lines
    to skip from the beginning of every file.  
    int值,一个默认为0,一个可选的选项使读取数据时跳过每个文件的开头skip_header_lines行
*  <b>`name`</b>: A name for the operation (optional).


- - -

#### `tf.TextLineReader.num_records_produced(name=None)` <a class="md-anchor" id="TextLineReader.num_records_produced"></a>

Returns the number of records this reader has produced.

This is the same as the number of Read executions that have
succeeded.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  An int64 Tensor.


- - -

#### `tf.TextLineReader.num_work_units_completed(name=None)` <a class="md-anchor" id="TextLineReader.num_work_units_completed"></a>

Returns the number of work units this reader has finished processing.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  An int64 Tensor.


- - -

#### `tf.TextLineReader.read(queue, name=None)` <a class="md-anchor" id="TextLineReader.read"></a>

Returns the next record (key, value pair) produced by a reader.  
返回阅读器读取的下一条记录(键值对形式)

Will dequeue a work unit from queue if necessary (e.g. when the
Reader needs to start reading from a new file since it has
finished with the previous file).  
如果有必要，将对队列中的工作单元进行排序(例如,阅读器已经完成了一部分内容,现在需要从下一条进行阅读时)。

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`queue`</b>: A Queue or a mutable string Tensor representing a handle
    to a Queue, with string work items.  
   代表文件名队列的句柄
*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  A tuple of Tensors (key, value).
  返回键值对
*  <b>`key`</b>: A string scalar Tensor.
*  <b>`value`</b>: A string scalar Tensor.


- - -

#### `tf.TextLineReader.reader_ref` <a class="md-anchor" id="TextLineReader.reader_ref"></a>

Op that implements the reader.

- - -

#### `tf.TextLineReader.reset(name=None)` <a class="md-anchor" id="TextLineReader.reset"></a>

Restore a reader to its initial clean state.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  The created Operation.


- - -

#### `tf.TextLineReader.restore_state(state, name=None)` <a class="md-anchor" id="TextLineReader.restore_state"></a>

Restore a reader to a previously saved state.

Not all Readers support being restored, so this can produce an
Unimplemented error.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`state`</b>: A string Tensor.
    Result of a SerializeState of a Reader with matching type.
*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  The created Operation.


- - -

#### `tf.TextLineReader.serialize_state(name=None)` <a class="md-anchor" id="TextLineReader.serialize_state"></a>

Produce a string tensor that encodes the state of a reader.

Not all Readers support being serialized, so this can produce an
Unimplemented error.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  A string Tensor.


- - -

#### `tf.TextLineReader.supports_serialize` <a class="md-anchor" id="TextLineReader.supports_serialize"></a>

Whether the Reader implementation can serialize its state.


- - -

### `class tf.WholeFileReader` <a class="md-anchor" id="WholeFileReader"></a>

A Reader that outputs the entire contents of a file as a value.

To use, enqueue filenames in a Queue.  The output of Read will
be a filename (key) and the contents of that file (value).  
将文件的全部内容输出为值的阅读器。

在队列中使用队列文件名。
读取的输出是文件名(键)和该文件的内容(值)。即是以键值对的形式输出值

请参阅ReaderBase以获得支持的方法。

See ReaderBase for supported methods.
- - -

#### `tf.WholeFileReader.__init__(name=None)` <a class="md-anchor" id="WholeFileReader.__init__"></a>

Create a WholeFileReader.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`name`</b>: A name for the operation (optional).


- - -

#### `tf.WholeFileReader.num_records_produced(name=None)` <a class="md-anchor" id="WholeFileReader.num_records_produced"></a>

Returns the number of records this reader has produced.

This is the same as the number of Read executions that have
succeeded.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  An int64 Tensor.


- - -

#### `tf.WholeFileReader.num_work_units_completed(name=None)` <a class="md-anchor" id="WholeFileReader.num_work_units_completed"></a>

Returns the number of work units this reader has finished processing.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  An int64 Tensor.


- - -

#### `tf.WholeFileReader.read(queue, name=None)` <a class="md-anchor" id="WholeFileReader.read"></a>

Returns the next record (key, value pair) produced by a reader.
返回一个阅读器生成的下一个记录(键值对)。
Will dequeue a work unit from queue if necessary (e.g. when the
Reader needs to start reading from a new file since it has
finished with the previous file).

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`queue`</b>: A Queue or a mutable string Tensor representing a handle
    to a Queue, with string work items.
*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  A tuple of Tensors (key, value).

*  <b>`key`</b>: A string scalar Tensor.
*  <b>`value`</b>: A string scalar Tensor.


- - -

#### `tf.WholeFileReader.reader_ref` <a class="md-anchor" id="WholeFileReader.reader_ref"></a>

Op that implements the reader.

- - -

#### `tf.WholeFileReader.reset(name=None)` <a class="md-anchor" id="WholeFileReader.reset"></a>

Restore a reader to its initial clean state.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  The created Operation.


- - -

#### `tf.WholeFileReader.restore_state(state, name=None)` <a class="md-anchor" id="WholeFileReader.restore_state"></a>

Restore a reader to a previously saved state.

Not all Readers support being restored, so this can produce an
Unimplemented error.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`state`</b>: A string Tensor.
    Result of a SerializeState of a Reader with matching type.
*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  The created Operation.


- - -

#### `tf.WholeFileReader.serialize_state(name=None)` <a class="md-anchor" id="WholeFileReader.serialize_state"></a>

Produce a string tensor that encodes the state of a reader.

Not all Readers support being serialized, so this can produce an
Unimplemented error.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  A string Tensor.


- - -

#### `tf.WholeFileReader.supports_serialize` <a class="md-anchor" id="WholeFileReader.supports_serialize"></a>

Whether the Reader implementation can serialize its state.


- - -

### `class tf.IdentityReader` <a class="md-anchor" id="IdentityReader"></a>

A Reader that outputs the queued work as both the key and value.

To use, enqueue strings in a Queue.  Read will take the front
work string and output (work, work).

See ReaderBase for supported methods.
- - -

#### `tf.IdentityReader.__init__(name=None)` <a class="md-anchor" id="IdentityReader.__init__"></a>

Create a IdentityReader.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`name`</b>: A name for the operation (optional).


- - -

#### `tf.IdentityReader.num_records_produced(name=None)` <a class="md-anchor" id="IdentityReader.num_records_produced"></a>

Returns the number of records this reader has produced.

This is the same as the number of Read executions that have
succeeded.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  An int64 Tensor.


- - -

#### `tf.IdentityReader.num_work_units_completed(name=None)` <a class="md-anchor" id="IdentityReader.num_work_units_completed"></a>

Returns the number of work units this reader has finished processing.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  An int64 Tensor.


- - -

#### `tf.IdentityReader.read(queue, name=None)` <a class="md-anchor" id="IdentityReader.read"></a>

Returns the next record (key, value pair) produced by a reader.

Will dequeue a work unit from queue if necessary (e.g. when the
Reader needs to start reading from a new file since it has
finished with the previous file).

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`queue`</b>: A Queue or a mutable string Tensor representing a handle
    to a Queue, with string work items.
*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  A tuple of Tensors (key, value).

*  <b>`key`</b>: A string scalar Tensor.
*  <b>`value`</b>: A string scalar Tensor.


- - -

#### `tf.IdentityReader.reader_ref` <a class="md-anchor" id="IdentityReader.reader_ref"></a>

Op that implements the reader.

- - -

#### `tf.IdentityReader.reset(name=None)` <a class="md-anchor" id="IdentityReader.reset"></a>

Restore a reader to its initial clean state.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  The created Operation.


- - -

#### `tf.IdentityReader.restore_state(state, name=None)` <a class="md-anchor" id="IdentityReader.restore_state"></a>

Restore a reader to a previously saved state.

Not all Readers support being restored, so this can produce an
Unimplemented error.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`state`</b>: A string Tensor.
    Result of a SerializeState of a Reader with matching type.
*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  The created Operation.


- - -

#### `tf.IdentityReader.serialize_state(name=None)` <a class="md-anchor" id="IdentityReader.serialize_state"></a>

Produce a string tensor that encodes the state of a reader.

Not all Readers support being serialized, so this can produce an
Unimplemented error.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  A string Tensor.


- - -

#### `tf.IdentityReader.supports_serialize` <a class="md-anchor" id="IdentityReader.supports_serialize"></a>

Whether the Reader implementation can serialize its state.


- - -

### `class tf.TFRecordReader` <a class="md-anchor" id="TFRecordReader"></a>

A Reader that outputs the records from a TFRecords file.

See ReaderBase for supported methods.
- - -

#### `tf.TFRecordReader.__init__(name=None)` <a class="md-anchor" id="TFRecordReader.__init__"></a>

Create a TFRecordReader.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`name`</b>: A name for the operation (optional).


- - -

#### `tf.TFRecordReader.num_records_produced(name=None)` <a class="md-anchor" id="TFRecordReader.num_records_produced"></a>

Returns the number of records this reader has produced.

This is the same as the number of Read executions that have
succeeded.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  An int64 Tensor.


- - -

#### `tf.TFRecordReader.num_work_units_completed(name=None)` <a class="md-anchor" id="TFRecordReader.num_work_units_completed"></a>

Returns the number of work units this reader has finished processing.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  An int64 Tensor.


- - -

#### `tf.TFRecordReader.read(queue, name=None)` <a class="md-anchor" id="TFRecordReader.read"></a>

Returns the next record (key, value pair) produced by a reader.

Will dequeue a work unit from queue if necessary (e.g. when the
Reader needs to start reading from a new file since it has
finished with the previous file).

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`queue`</b>: A Queue or a mutable string Tensor representing a handle
    to a Queue, with string work items.
*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  A tuple of Tensors (key, value).

*  <b>`key`</b>: A string scalar Tensor.
*  <b>`value`</b>: A string scalar Tensor.


- - -

#### `tf.TFRecordReader.reader_ref` <a class="md-anchor" id="TFRecordReader.reader_ref"></a>

Op that implements the reader.

- - -

#### `tf.TFRecordReader.reset(name=None)` <a class="md-anchor" id="TFRecordReader.reset"></a>

Restore a reader to its initial clean state.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  The created Operation.


- - -

#### `tf.TFRecordReader.restore_state(state, name=None)` <a class="md-anchor" id="TFRecordReader.restore_state"></a>

Restore a reader to a previously saved state.

Not all Readers support being restored, so this can produce an
Unimplemented error.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`state`</b>: A string Tensor.
    Result of a SerializeState of a Reader with matching type.
*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  The created Operation.


- - -

#### `tf.TFRecordReader.serialize_state(name=None)` <a class="md-anchor" id="TFRecordReader.serialize_state"></a>

Produce a string tensor that encodes the state of a reader.

Not all Readers support being serialized, so this can produce an
Unimplemented error.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  A string Tensor.


- - -

#### `tf.TFRecordReader.supports_serialize` <a class="md-anchor" id="TFRecordReader.supports_serialize"></a>

Whether the Reader implementation can serialize its state.


- - -

### `class tf.FixedLengthRecordReader` <a class="md-anchor" id="FixedLengthRecordReader"></a>

A Reader that outputs fixed-length records from a file.

See ReaderBase for supported methods.
- - -

#### `tf.FixedLengthRecordReader.__init__(record_bytes, header_bytes=None, footer_bytes=None, name=None)` <a class="md-anchor" id="FixedLengthRecordReader.__init__"></a>

Create a FixedLengthRecordReader.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`record_bytes`</b>: An int.
*  <b>`header_bytes`</b>: An optional int. Defaults to 0.
*  <b>`footer_bytes`</b>: An optional int. Defaults to 0.
*  <b>`name`</b>: A name for the operation (optional).


- - -

#### `tf.FixedLengthRecordReader.num_records_produced(name=None)` <a class="md-anchor" id="FixedLengthRecordReader.num_records_produced"></a>

Returns the number of records this reader has produced.

This is the same as the number of Read executions that have
succeeded.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  An int64 Tensor.


- - -

#### `tf.FixedLengthRecordReader.num_work_units_completed(name=None)` <a class="md-anchor" id="FixedLengthRecordReader.num_work_units_completed"></a>

Returns the number of work units this reader has finished processing.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  An int64 Tensor.


- - -

#### `tf.FixedLengthRecordReader.read(queue, name=None)` <a class="md-anchor" id="FixedLengthRecordReader.read"></a>

Returns the next record (key, value pair) produced by a reader.

Will dequeue a work unit from queue if necessary (e.g. when the
Reader needs to start reading from a new file since it has
finished with the previous file).

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`queue`</b>: A Queue or a mutable string Tensor representing a handle
    to a Queue, with string work items.
*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  A tuple of Tensors (key, value).

*  <b>`key`</b>: A string scalar Tensor.
*  <b>`value`</b>: A string scalar Tensor.


- - -

#### `tf.FixedLengthRecordReader.reader_ref` <a class="md-anchor" id="FixedLengthRecordReader.reader_ref"></a>

Op that implements the reader.

- - -

#### `tf.FixedLengthRecordReader.reset(name=None)` <a class="md-anchor" id="FixedLengthRecordReader.reset"></a>

Restore a reader to its initial clean state.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  The created Operation.


- - -

#### `tf.FixedLengthRecordReader.restore_state(state, name=None)` <a class="md-anchor" id="FixedLengthRecordReader.restore_state"></a>

Restore a reader to a previously saved state.

Not all Readers support being restored, so this can produce an
Unimplemented error.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`state`</b>: A string Tensor.
    Result of a SerializeState of a Reader with matching type.
*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  The created Operation.


- - -

#### `tf.FixedLengthRecordReader.serialize_state(name=None)` <a class="md-anchor" id="FixedLengthRecordReader.serialize_state"></a>

Produce a string tensor that encodes the state of a reader.

Not all Readers support being serialized, so this can produce an
Unimplemented error.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  A string Tensor.


- - -

#### `tf.FixedLengthRecordReader.supports_serialize` <a class="md-anchor" id="FixedLengthRecordReader.supports_serialize"></a>

Whether the Reader implementation can serialize its state.



## Converting <a class="md-anchor" id="AUTOGENERATED-converting"></a>

TensorFlow provides several operations that you can use to convert various data
formats into tensors.

- - -

### `tf.decode_csv(records, record_defaults, field_delim=None, name=None)` <a class="md-anchor" id="decode_csv"></a>

Convert CSV records to tensors. Each column maps to one tensor.  
将CSV记录转换为张量。每一列都映射到一个张量。records默认为字符串形式

RFC 4180 format is expected for the CSV records.
(https://tools.ietf.org/html/rfc4180)
Note that we allow leading and trailing spaces with int or float field.
请注意，我们允许带int或float字段的开头和尾附有空格。
##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`records`</b>: A `Tensor` of type `string`.
    Each string is a record/row in the csv and all records should have
    the same format.每个字符串都是csv中的记录/行，所有记录都应该具有相同的格式。
*  <b>`record_defaults`</b>: A list of `Tensor` objects with types from: `float32`, `int32`, `int64`, `string`.
    One tensor per column of the input record, with either a
    scalar default value for that column or empty if the column is required.  
    输入记录的每一列的一个张量，用于表示空白列的默认标量值.  
    由于数据类型必须相同的缘故,这里也间接的指示了整个csv文件默认的数据类型.
*  <b>`field_delim`</b>: An optional `string`. Defaults to `","`.
    delimiter to separate fields in a record.分隔符来分隔记录中的字段。
*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  A list of `Tensor` objects. Has the same type as `record_defaults`.
  Each tensor will have the same shape as records.  
  返回一个tensor对象的列表,并且每个和"record_defaults"含有相同的类型,作为结果的每个张量会有相同的shape


- - -

### `tf.decode_raw(bytes, out_type, little_endian=None, name=None)` <a class="md-anchor" id="decode_raw"></a>

Reinterpret the bytes of a string as a vector of numbers.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`bytes`</b>: A `Tensor` of type `string`.
    All the elements must have the same length.
*  <b>`out_type`</b>: A `tf.DType` from: `tf.float32, tf.float64, tf.int32, tf.uint8, tf.int16, tf.int8, tf.int64`.
*  <b>`little_endian`</b>: An optional `bool`. Defaults to `True`.
    Whether the input bytes are in little-endian order.
    Ignored for out_types that are stored in a single byte like uint8.
*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  A `Tensor` of type `out_type`.
  A Tensor with one more dimension than the input bytes.  The
  added dimension will have size equal to the length of the elements
  of bytes divided by the number of bytes to represent out_type.



- - -

### Example protocol buffer <a class="md-anchor" id="AUTOGENERATED-example-protocol-buffer"></a>

TensorFlow's [recommended format for training
examples](../../how_tos/reading_data/index.md#standard-tensorflow-format)
is serialized `Example` protocol buffers, [described
here](https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/core/example/example.proto).
They contain `Features`, [described
here](https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/core/example/feature.proto).

- - -

### `tf.parse_example(serialized, names=None, sparse_keys=None, sparse_types=None, dense_keys=None, dense_types=None, dense_defaults=None, dense_shapes=None, name='ParseExample')` <a class="md-anchor" id="parse_example"></a>

Parses `Example` protos.

Parses a number of serialized [`Example`]
(https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/core/example/example.proto)
protos given in `serialized`.

`names` may contain descriptive names for the corresponding serialized protos.
These may be useful for debugging purposes, but they have no effect on the
output. If not `None`, `names` must be the same length as `serialized`.

This op parses serialized examples into a dictionary mapping keys to `Tensor`
and `SparseTensor` objects respectively, depending on whether the keys appear
in `sparse_keys` or `dense_keys`.

The key `dense_keys[j]` is mapped to a `Tensor` of type `dense_types[j]` and
of shape `(serialized.size(),) + dense_shapes[j]`.

`dense_defaults` provides defaults for values referenced using `dense_keys`.
If a key is not present in this dictionary, the corresponding dense `Feature`
is required in all elements of `serialized`.

`dense_shapes[j]` provides the shape of each `Feature` entry referenced by
`dense_keys[j]`. The number of elements in the `Feature` corresponding to
`dense_key[j]` must always have `np.prod(dense_shapes[j])` entries. The
returned `Tensor` for `dense_key[j]` has shape `[N] + dense_shape[j]`, where
`N` is the number of `Example`s in `serialized`.

The key `sparse_keys[j]` is mapped to a `SparseTensor` of type
`sparse_types[j]`. The `SparseTensor` represents a ragged matrix.
Its indices are `[batch, index]` where `batch` is the batch entry the value
is from, and `index` is the value's index in the list of values associated
with that feature and example.

Examples:

For example, if one expects a `tf.float32` sparse feature `ft` and three
serialized `Example`s are provided:

```
serialized = [
  features:
    { feature: [ key: { "ft" value: float_list: { value: [1.0, 2.0] } } ] },
  features:
    { feature: [] },
  features:
    { feature: [ key: { "ft" value: float_list: { value: [3.0] } } ] }
]
```

then the output will look like:

```
{"ft": SparseTensor(indices=[[0, 0], [0, 1], [2, 0]],
                    values=[1.0, 2.0, 3.0],
                    shape=(3, 2)) }
```

Given two `Example` input protos in `serialized`:

```
[
  features: {
    feature: { key: "kw" value: { bytes_list: { value: [ "knit", "big" ] } } }
    feature: { key: "gps" value: { float_list: { value: [] } } }
  },
  features: {
    feature: { key: "kw" value: { bytes_list: { value: [ "emmy" ] } } }
    feature: { key: "dank" value: { int64_list: { value: [ 42 ] } } }
    feature: { key: "gps" value: { } }
  }
]
```

And arguments

```
  names: ["input0", "input1"],
  sparse_keys: ["kw", "dank", "gps"]
  sparse_types: [DT_STRING, DT_INT64, DT_FLOAT]
```

Then the output is a dictionary:

```python
{
  "kw": SparseTensor(
      indices=[[0, 0], [0, 1], [1, 0]],
      values=["knit", "big", "emmy"]
      shape=[2, 2]),
  "dank": SparseTensor(
      indices=[[1, 0]],
      values=[42],
      shape=[2, 1]),
  "gps": SparseTensor(
      indices=[],
      values=[],
      shape=[2, 0]),
}
```

For dense results in two serialized `Example`s:

```
[
  features: {
    feature: { key: "age" value: { int64_list: { value: [ 0 ] } } }
    feature: { key: "gender" value: { bytes_list: { value: [ "f" ] } } }
   },
   features: {
    feature: { key: "age" value: { int64_list: { value: [] } } }
    feature: { key: "gender" value: { bytes_list: { value: [ "f" ] } } }
  }
]
```

We can use arguments:

```
names: ["input0", "input1"],
dense_keys: np.array(["age", "gender"]),
dense_types: [tf.int64, tf.string],
dense_defaults: {
  "age": -1  # "age" defaults to -1 if missing
             # "gender" has no specified default so it's required
}
dense_shapes: [(1,), (1,)],  # age, gender, label, weight
```

And the expected output is:

```python
{
  "age": [[0], [-1]],
  "gender": [["f"], ["f"]],
}
```

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`serialized`</b>: A list of strings, a batch of binary serialized `Example`
    protos.
*  <b>`names`</b>: A list of strings, the names of the serialized protos.
*  <b>`sparse_keys`</b>: A list of string keys in the examples' features.
    The results for these keys will be returned as `SparseTensor` objects.
*  <b>`sparse_types`</b>: A list of `DTypes` of the same length as `sparse_keys`.
    Only `tf.float32` (`FloatList`), `tf.int64` (`Int64List`),
    and `tf.string` (`BytesList`) are supported.
*  <b>`dense_keys`</b>: A list of string keys in the examples' features.
    The results for these keys will be returned as `Tensor`s
*  <b>`dense_types`</b>: A list of DTypes of the same length as `dense_keys`.
    Only `tf.float32` (`FloatList`), `tf.int64` (`Int64List`),
    and `tf.string` (`BytesList`) are supported.
*  <b>`dense_defaults`</b>: A dict mapping string keys to `Tensor`s.
    The keys of the dict must match the dense_keys of the feature.
*  <b>`dense_shapes`</b>: A list of tuples with the same length as `dense_keys`.
    The shape of the data for each dense feature referenced by `dense_keys`.
*  <b>`name`</b>: A name for this operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  A `dict` mapping keys to `Tensor`s and `SparseTensor`s.

##### Raises: <a class="md-anchor" id="AUTOGENERATED-raises-"></a>


*  <b>`ValueError`</b>: If sparse and dense key sets intersect, or input lengths do not
    match up.


- - -

### `tf.parse_single_example(serialized, names=None, sparse_keys=None, sparse_types=None, dense_keys=None, dense_types=None, dense_defaults=None, dense_shapes=None, name='ParseSingleExample')` <a class="md-anchor" id="parse_single_example"></a>

Parses a single `Example` proto.

Similar to `parse_example`, except:

For dense tensors, the returned `Tensor` is identical to the output of
`parse_example`, except there is no batch dimension, the output shape is the
same as the shape given in `dense_shape`.

For `SparseTensor`s, the first (batch) column of the indices matrix is removed
(the indices matrix is a column vector), the values vector is unchanged, and
the first (batch_size) entry of the shape vector is removed (it is now a
single element vector).

See also `parse_example`.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`serialized`</b>: A scalar string, a single serialized Example.
    See parse_example documentation for more details.
*  <b>`names`</b>: (Optional) A scalar string, the associated name.
    See parse_example documentation for more details.
*  <b>`sparse_keys`</b>: See parse_example documentation for more details.
*  <b>`sparse_types`</b>: See parse_example documentation for more details.
*  <b>`dense_keys`</b>: See parse_example documentation for more details.
*  <b>`dense_types`</b>: See parse_example documentation for more details.
*  <b>`dense_defaults`</b>: See parse_example documentation for more details.
*  <b>`dense_shapes`</b>: See parse_example documentation for more details.
*  <b>`name`</b>: A name for this operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  A dictionary mapping keys to Tensors and SparseTensors.

##### Raises: <a class="md-anchor" id="AUTOGENERATED-raises-"></a>


*  <b>`ValueError`</b>: if "scalar" or "names" have known shapes, and are not scalars.



## Queues <a class="md-anchor" id="AUTOGENERATED-queues"></a>

TensorFlow provides several implementations of 'Queues', which are
structures within the TensorFlow computation graph to stage pipelines
of tensors together. The following describe the basic Queue interface
and some implementations.  To see an example use, see [Threading and
Queues](../../how_tos/threading_and_queues/index.md).

- - -

### `class tf.QueueBase` <a class="md-anchor" id="QueueBase"></a>

Base class for queue implementations.

A queue is a TensorFlow data structure that stores tensors across
multiple steps, and exposes operations that enqueue and dequeue
tensors.

Each queue element is a tuple of one or more tensors, where each
tuple component has a static dtype, and may have a static shape. The
queue implementations support versions of enqueue and dequeue that
handle single elements, versions that support enqueuing and
dequeuing a batch of elements at once.

See [`tf.FIFOQueue`](#FIFOQueue) and
[`tf.RandomShuffleQueue`](#RandomShuffleQueue) for concrete
implementations of this class, and instructions on how to create
them.

- - -

#### `tf.QueueBase.enqueue(vals, name=None)` <a class="md-anchor" id="QueueBase.enqueue"></a>

Enqueues one element to this queue.

If the queue is full when this operation executes, it will block
until the element has been enqueued.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`vals`</b>: The tuple of `Tensor` objects to be enqueued.
*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  The operation that enqueues a new tuple of tensors to the queue.


- - -

#### `tf.QueueBase.enqueue_many(vals, name=None)` <a class="md-anchor" id="QueueBase.enqueue_many"></a>

Enqueues zero or elements to this queue.

This operation slices each component tensor along the 0th dimension to
make multiple queue elements. All of the tensors in `vals` must have the
same size in the 0th dimension.

If the queue is full when this operation executes, it will block
until all of the elements have been enqueued.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`vals`</b>: The tensor or tuple of tensors from which the queue elements
    are taken.
*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  The operation that enqueues a batch of tuples of tensors to the queue.



- - -

#### `tf.QueueBase.dequeue(name=None)` <a class="md-anchor" id="QueueBase.dequeue"></a>

Dequeues one element from this queue.

If the queue is empty when this operation executes, it will block
until there is an element to dequeue.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  The tuple of tensors that was dequeued.


- - -

#### `tf.QueueBase.dequeue_many(n, name=None)` <a class="md-anchor" id="QueueBase.dequeue_many"></a>

Dequeues and concatenates `n` elements from this queue.

This operation concatenates queue-element component tensors along
the 0th dimension to make a single component tensor.  All of the
components in the dequeued tuple will have size `n` in the 0th dimension.

If the queue contains fewer than `n` elements when this operation
executes, it will block until `n` elements have been dequeued.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`n`</b>: A scalar `Tensor` containing the number of elements to dequeue.
*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  The tuple of concatenated tensors that was dequeued.



- - -

#### `tf.QueueBase.size(name=None)` <a class="md-anchor" id="QueueBase.size"></a>

Compute the number of elements in this queue.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  A scalar tensor containing the number of elements in this queue.



- - -

#### `tf.QueueBase.close(cancel_pending_enqueues=False, name=None)` <a class="md-anchor" id="QueueBase.close"></a>

Closes this queue.

This operation signals that no more elements will be enqueued in
the given queue. Subsequent `enqueue` and `enqueue_many`
operations will fail. Subsequent `dequeue` and `dequeue_many`
operations will continue to succeed if sufficient elements remain
in the queue. Subsequent `dequeue` and `dequeue_many` operations
that would block will fail immediately.

If `cancel_pending_enqueues` is `True`, all pending requests will also
be cancelled.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`cancel_pending_enqueues`</b>: (Optional.) A boolean, defaulting to
    `False` (described above).
*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  The operation that closes the queue.



#### Other Methods <a class="md-anchor" id="AUTOGENERATED-other-methods"></a>
- - -

#### `tf.QueueBase.__init__(dtypes, shapes, queue_ref)` <a class="md-anchor" id="QueueBase.__init__"></a>

Constructs a queue object from a queue reference.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`dtypes`</b>: A list of types.  The length of dtypes must equal the number
    of tensors in each element.
*  <b>`shapes`</b>: Constraints on the shapes of tensors in an element:
    A list of shape tuples or None. This list is the same length
    as dtypes.  If the shape of any tensors in the element are constrained,
    all must be; shapes can be None if the shapes should not be constrained.
*  <b>`queue_ref`</b>: The queue reference, i.e. the output of the queue op.


- - -

#### `tf.QueueBase.dtypes` <a class="md-anchor" id="QueueBase.dtypes"></a>

The list of dtypes for each component of a queue element.

- - -

#### `tf.QueueBase.name` <a class="md-anchor" id="QueueBase.name"></a>

The name of the underlying queue.

- - -

#### `tf.QueueBase.queue_ref` <a class="md-anchor" id="QueueBase.queue_ref"></a>

The underlying queue reference.


- - -

### `class tf.FIFOQueue` <a class="md-anchor" id="FIFOQueue"></a>

A queue implementation that dequeues elements in first-in-first out order.

See [`tf.QueueBase`](#QueueBase) for a description of the methods on
this class.

- - -

#### `tf.FIFOQueue.__init__(capacity, dtypes, shapes=None, shared_name=None, name='fifo_queue')` <a class="md-anchor" id="FIFOQueue.__init__"></a>

Creates a queue that dequeues elements in a first-in first-out order.

A `FIFOQueue` has bounded capacity; supports multiple concurrent
producers and consumers; and provides exactly-once delivery.

A `FIFOQueue` holds a list of up to `capacity` elements. Each
element is a fixed-length tuple of tensors whose dtypes are
described by `dtypes`, and whose shapes are optionally described
by the `shapes` argument.

If the `shapes` argument is specified, each component of a queue
element must have the respective fixed shape. If it is
unspecified, different queue elements may have different shapes,
but the use of `dequeue_many` is disallowed.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`capacity`</b>: An integer. The upper bound on the number of elements
    that may be stored in this queue.
*  <b>`dtypes`</b>: A list of `DType` objects. The length of `dtypes` must equal
    the number of tensors in each queue element.
*  <b>`shapes`</b>: (Optional.) A list of fully-defined `TensorShape` objects,
    with the same length as `dtypes` or `None`.
*  <b>`shared_name`</b>: (Optional.) If non-empty, this queue will be shared under
    the given name across multiple sessions.
*  <b>`name`</b>: Optional name for the queue operation.



- - -

### `class tf.RandomShuffleQueue` <a class="md-anchor" id="RandomShuffleQueue"></a>

A queue implementation that dequeues elements in a random order.

See [`tf.QueueBase`](#QueueBase) for a description of the methods on
this class.

- - -

#### `tf.RandomShuffleQueue.__init__(capacity, min_after_dequeue, dtypes, shapes=None, seed=None, shared_name=None, name='random_shuffle_queue')` <a class="md-anchor" id="RandomShuffleQueue.__init__"></a>

Create a queue that dequeues elements in a random order.

A `RandomShuffleQueue` has bounded capacity; supports multiple
concurrent producers and consumers; and provides exactly-once
delivery.

A `RandomShuffleQueue` holds a list of up to `capacity`
elements. Each element is a fixed-length tuple of tensors whose
dtypes are described by `dtypes`, and whose shapes are optionally
described by the `shapes` argument.

If the `shapes` argument is specified, each component of a queue
element must have the respective fixed shape. If it is
unspecified, different queue elements may have different shapes,
but the use of `dequeue_many` is disallowed.

The `min_after_dequeue` argument allows the caller to specify a
minimum number of elements that will remain in the queue after a
`dequeue` or `dequeue_many` operation completes, to ensure a
minimum level of mixing of elements. This invariant is maintained
by blocking those operations until sufficient elements have been
enqueued. The `min_after_dequeue` argument is ignored after the
queue has been closed.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`capacity`</b>: An integer. The upper bound on the number of elements
    that may be stored in this queue.
*  <b>`min_after_dequeue`</b>: An integer (described above).
*  <b>`dtypes`</b>: A list of `DType` objects. The length of `dtypes` must equal
    the number of tensors in each queue element.
*  <b>`shapes`</b>: (Optional.) A list of fully-defined `TensorShape` objects,
    with the same length as `dtypes` or `None`.
*  <b>`seed`</b>: A Python integer. Used to create a random seed. See
    [`set_random_seed`](../../api_docs/python/constant_op.md#set_random_seed)
    for behavior.
*  <b>`shared_name`</b>: (Optional.) If non-empty, this queue will be shared under
    the given name across multiple sessions.
*  <b>`name`</b>: Optional name for the queue operation.




## Dealing with the filesystem <a class="md-anchor" id="AUTOGENERATED-dealing-with-the-filesystem"></a>

- - -

### `tf.matching_files(pattern, name=None)` <a class="md-anchor" id="matching_files"></a>

Returns the set of files matching a pattern.

Note that this routine only supports wildcard characters in the
basename portion of the pattern, not in the directory portion.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`pattern`</b>: A `Tensor` of type `string`. A (scalar) shell wildcard pattern.
*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  A `Tensor` of type `string`. A vector of matching filenames.


- - -

### `tf.read_file(filename, name=None)` <a class="md-anchor" id="read_file"></a>

Reads and outputs the entire contents of the input filename.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`filename`</b>: A `Tensor` of type `string`.
*  <b>`name`</b>: A name for the operation (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  A `Tensor` of type `string`.



## Input pipeline <a class="md-anchor" id="AUTOGENERATED-input-pipeline"></a>

TensorFlow functions for setting up an input-prefetching pipeline.
Please see the [reading data how-to](../../how_tos/reading_data/index.md)
for context.

### Beginning of an input pipeline <a class="md-anchor" id="AUTOGENERATED-beginning-of-an-input-pipeline"></a>

The "producer" functions add a queue to the graph and a corresponding
`QueueRunner` for running the subgraph that fills that queue.

- - -

### `tf.train.match_filenames_once(pattern, name=None)` <a class="md-anchor" id="match_filenames_once"></a>

Save the list of files matching pattern, so it is only computed once.  
保存文件匹配模式的列表，因此只计算一次。 用于产生文件名列表.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`pattern`</b>: A file pattern (glob),or 1D tensor of file patterns.  
    一个文件模式或者一个文件模式1维张量
*  <b>`name`</b>: A name for the operations (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  A variable that is initialized to the list of files matching pattern.  
  一个被初始化到文件匹配模式列表的变量。


- - -

### `tf.train.limit_epochs(tensor, num_epochs=None, name=None)` <a class="md-anchor" id="limit_epochs"></a>

Returns tensor num_epochs times and then raises an OutOfRange error.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`tensor`</b>: Any Tensor.
*  <b>`num_epochs`</b>: An integer (optional).  If specified, limits the number
    of steps the output tensor may be evaluated.
*  <b>`name`</b>: A name for the operations (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  tensor or OutOfRange.


- - -

### `tf.train.range_input_producer(limit, num_epochs=None, shuffle=True, seed=None, capacity=32, name=None)` <a class="md-anchor" id="range_input_producer"></a>

Produces the integers from 0 to limit-1 in a queue.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`limit`</b>: An int32 scalar tensor.
*  <b>`num_epochs`</b>: An integer (optional). If specified, `range_input_producer`
    produces each integer `num_epochs` times before generating an
    OutOfRange error. If not specified, `range_input_producer` can cycle
    through the integers an unlimited number of times.
*  <b>`shuffle`</b>: Boolean. If true, the integers are randomly shuffled within each
    epoch.
*  <b>`seed`</b>: An integer (optional). Seed used if shuffle == True.
*  <b>`capacity`</b>: An integer. Sets the queue capacity.
*  <b>`name`</b>: A name for the operations (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  A Queue with the output integers.  A QueueRunner for the Queue
  is added to the current Graph's QUEUE_RUNNER collection.


- - -

### `tf.train.slice_input_producer(tensor_list, num_epochs=None, shuffle=True, seed=None, capacity=32, name=None)` <a class="md-anchor" id="slice_input_producer"></a>

Produces a slice of each Tensor in tensor_list.

Implemented using a Queue -- a QueueRunner for the Queue
is added to the current Graph's QUEUE_RUNNER collection.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`tensor_list`</b>: A list of Tensors. Every Tensor in tensor_list must
    have the same size in the first dimension.
*  <b>`num_epochs`</b>: An integer (optional). If specified, `slice_input_producer`
    produces each slice `num_epochs` times before generating
    an OutOfRange error. If not specified, `slice_input_producer` can cycle
    through the slices an unlimited number of times.
*  <b>`seed`</b>: An integer (optional). Seed used if shuffle == True.
*  <b>`capacity`</b>: An integer. Sets the queue capacity.
*  <b>`name`</b>: A name for the operations (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  A list of tensors, one for each element of tensor_list.  If the tensor
  in tensor_list has shape [N, a, b, .., z], then the corresponding output
  tensor will have shape [a, b, ..., z].


- - -

### `tf.train.string_input_producer(string_tensor, num_epochs=None, shuffle=True, seed=None, capacity=32, name=None)` <a class="md-anchor" id="string_input_producer"></a>

Output strings (e.g. filenames) to a queue for an input pipeline.  
对于输入的文件名列表,此函数会生成一个先入先出的队列,文件阅读器利用其来读取数据.  
可以通过提供的可配置参数来设置文件名乱序和最大的训练迭代数

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`string_tensor`</b>: A 1-D string tensor with the strings to produce.  
    文件名序列
*  <b>`num_epochs`</b>: An integer (optional). If specified, `string_input_producer`
    produces each string from `string_tensor` `num_epochs` times before
    generating an OutOfRange error. If not specified, `string_input_producer`
    can cycle through the strings in `string_tensor` an unlimited number of
    times.  
    int类型数据,如果指定在num_epochs指定次数内读取文件名列表的文件名,如果不指定则会无限次循环读取文件名
*  <b>`shuffle`</b>: Boolean. If true, the strings are randomly shuffled within each
    epoch.  
    布尔类型数据,如果设置为真,会对每一epoch中得数据进行乱序处理
*  <b>`seed`</b>: An integer (optional). Seed used if shuffle == True.  
  用于乱序处理的seed
*  <b>`capacity`</b>: An integer. Sets the queue capacity.  
  int类型,设置队列的容量
*  <b>`name`</b>: A name for the operations (optional).

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  A queue with the output strings.  A QueueRunner for the Queue
  is added to the current Graph's QUEUE_RUNNER collection.



### Batching at the end of an input pipeline <a class="md-anchor" id="AUTOGENERATED-batching-at-the-end-of-an-input-pipeline"></a>

These functions add a queue to the graph to assemble a batch of examples, with
possible shuffling.  They also add a `QueueRunner` for running the subgraph
that fills that queue.

Use [batch](#batch) or [batch_join](#batch_join) for batching examples that have
already been well shuffled.  Use [shuffle_batch](#shuffle_batch) or
[shuffle_batch_join](#shuffle_batch_join) for examples that
would benefit from additional shuffling.

Use [batch](#batch) or [shuffle_batch](#shuffle_batch) if you want a
single thread producing examples to batch, or if you have a
single subgraph producing examples but you want to run it in N threads
(where you increase N until it can keep the queue full).  Use
[batch_join](#batch_join) or [shuffle_batch_join](#shuffle_batch_join)
if you have N different subgraphs producing examples to batch and you
want them run by N threads.

- - -

### `tf.train.batch(tensor_list, batch_size, num_threads=1, capacity=32, enqueue_many=False, shapes=None, name=None)` <a class="md-anchor" id="batch"></a>

Creates batches of tensors in `tensor_list`.

This function is implemented using a queue. A `QueueRunner` for the
queue is added to the current `Graph`'s `QUEUE_RUNNER` collection.

If `enqueue_many` is `False`, `tensor_list` is assumed to represent a
single example.  An input tensor with shape `[x, y, z]` will be output
as a tensor with shape `[batch_size, x, y, z]`.

If `enqueue_many` is `True`, `tensor_list` is assumed to represent a
batch of examples, where the first dimension is indexed by example,
and all members of `tensor_list` should have the same size in the
first dimension.  If an input tensor has shape `[*, x, y, z]`, the
output will have shape `[batch_size, x, y, z]`.  The `capacity` argument
controls the how long the prefetching is allowed to grow the queues.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`tensor_list`</b>: The list of tensors to enqueue.
*  <b>`batch_size`</b>: The new batch size pulled from the queue.
*  <b>`num_threads`</b>: The number of threads enqueuing `tensor_list`.
*  <b>`capacity`</b>: An integer. The maximum number of elements in the queue.
*  <b>`enqueue_many`</b>: Whether each tensor in `tensor_list` is a single example.
*  <b>`shapes`</b>: (Optional) The shapes for each example.  Defaults to the
    inferred shapes for `tensor_list`.
*  <b>`name`</b>: (Optional) A name for the operations.

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  A list of tensors with the same number and types as `tensor_list`.


- - -

### `tf.train.batch_join(tensor_list_list, batch_size, capacity=32, enqueue_many=False, shapes=None, name=None)` <a class="md-anchor" id="batch_join"></a>

Runs a list of tensors to fill a queue to create batches of examples.

Enqueues a different list of tensors in different threads.
Implemented using a queue -- a `QueueRunner` for the queue
is added to the current `Graph`'s `QUEUE_RUNNER` collection.

`len(tensor_list_list)` threads will be started,
with thread `i` enqueuing the tensors from
`tensor_list_list[i]`. `tensor_list_list[i1][j]` must match
`tensor_list_list[i2][j]` in type and shape, except in the first
dimension if `enqueue_many` is true.

If `enqueue_many` is `False`, each `tensor_list_list[i]` is assumed
to represent a single example. An input tensor `x` will be output as a
tensor with shape `[batch_size] + x.shape`.

If `enqueue_many` is `True`, `tensor_list_list[i]` is assumed to
represent a batch of examples, where the first dimension is indexed
by example, and all members of `tensor_list_list[i]` should have the
same size in the first dimension.  The slices of any input tensor
`x` are treated as examples, and the output tensors will have shape
`[batch_size] + x.shape[1:]`.

The `capacity` argument controls the how long the prefetching is allowed to
grow the queues.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`tensor_list_list`</b>: A list of tuples of tensors to enqueue.
*  <b>`batch_size`</b>: An integer. The new batch size pulled from the queue.
*  <b>`capacity`</b>: An integer. The maximum number of elements in the queue.
*  <b>`enqueue_many`</b>: Whether each tensor in `tensor_list_list` is a single
    example.
*  <b>`shapes`</b>: (Optional) The shapes for each example.  Defaults to the
    inferred shapes for `tensor_list_list[i]`.
*  <b>`name`</b>: (Optional) A name for the operations.

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  A list of tensors with the same number and types as
  `tensor_list_list[i]`.


- - -

### `tf.train.shuffle_batch(tensor_list, batch_size, capacity, min_after_dequeue, num_threads=1, seed=None, enqueue_many=False, shapes=None, name=None)` <a class="md-anchor" id="shuffle_batch"></a>

Creates batches by randomly shuffling tensors.  
通过随机打乱张量的顺序创建批次.  
### 简单来说就是读取一个文件并且加载一个张量中的batch_size行

This function adds the following to the current `Graph`:
这个函数将以下内容加入到现有的图中.
* A shuffling queue into which tensors from `tensor_list` are enqueued.  
一个由传入张量组成的随机乱序队列
* A `dequeue_many` operation to create batches from the queue.  
从张量队列中取出张量的出队操作
* A `QueueRunner` to `QUEUE_RUNNER` collection, to enqueue the tensors
  from `tensor_list`.
一个队列运行器管理出队操作.
If `enqueue_many` is `False`, `tensor_list` is assumed to represent a
single example.  An input tensor with shape `[x, y, z]` will be output
as a tensor with shape `[batch_size, x, y, z]`.  


If `enqueue_many` is `True`, `tensor_list` is assumed to represent a
batch of examples, where the first dimension is indexed by example,
and all members of `tensor_list` should have the same size in the
first dimension.  If an input tensor has shape `[*, x, y, z]`, the
output will have shape `[batch_size, x, y, z]`.
'enqueue_many'主要是设置tensor中的数据是否能重复,如果想要实现同一个样本多次出现可以将其设置为:"True",如果只想要其出现一次,也就是保持数据的唯一性,这时候我们将其设置为默认值:"False"
The `capacity` argument controls the how long the prefetching is allowed to
grow the queues.
容量控制了预抓取操作对于增加队列长度操作的长度.
For example:

```python
# Creates batches of 32 images and 32 labels.
image_batch, label_batch = tf.train.shuffle_batch(
      [single_image, single_label],
      batch_size=32,
      num_threads=4,
      capacity=50000,
      min_after_dequeue=10000)
```

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`tensor_list`</b>: The list of tensors to enqueue.    
入队的张量列表
*  <b>`batch_size`</b>: The new batch size pulled from the queue.  
表示进行一次批处理的tensors数量.
*  <b>`capacity`</b>: An integer. The maximum number of elements in the queue.  
容量:一个整数,队列中的最大的元素数.  
这个参数一定要比min_after_dequeue参数的值大,并且决定了我们可以进行预处理操作元素的最大值.
推荐其值为:
$$capacity=(min\_after\_dequeue+(num\_threads+a\ small\ safety\  margin*batch_size)$$

*  <b>`min_after_dequeue`</b>: Minimum number elements in the queue after a
    dequeue(出列), used to ensure a level of mixing of elements.  
    当一次出列操作完成后,队列中元素的最小数量,往往用于定义元素的混合级别.  

    定义了随机取样的缓冲区大小,此参数越大表示更大级别的混合但是会导致启动更加缓慢,并且会占用更多的内存
*  <b>`num_threads`</b>: The number of threads enqueuing `tensor_list`.  
设置num_threads的值大于1,使用多个线程在tensor_list中读取文件,这样保证了同一时刻只在一个文件中进行读取操作(但是读取速度依然优于单线程),而不是之前的同时读取多个文件,这种方案的优点是:
1. 避免了两个不同的线程从同一文件中读取用一个样本
2. 避免了过多的磁盘操作
*  <b>`seed`</b>: Seed for the random shuffling within the queue.  
打乱tensor队列的随机数种子
*  <b>`enqueue_many`</b>: Whether each tensor in `tensor_list` is a single example.  
定义tensor_list中的tensor是否冗余.
*  <b>`shapes`</b>: (Optional) The shapes for each example.  Defaults to the
    inferred shapes for `tensor_list`.  
用于改变读取tensor的形状,默认情况下和直接读取的tensor的形状一致.
*  <b>`name`</b>: (Optional) A name for the operations.

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  A list of tensors with the same number and types as `tensor_list`.  
  默认返回一个和读取tensor_list数据和类型一个tensor列表.

- - -

### `tf.train.shuffle_batch_join(tensor_list_list, batch_size, capacity, min_after_dequeue, seed=None, enqueue_many=False, shapes=None, name=None)` <a class="md-anchor" id="shuffle_batch_join"></a>

Create batches by randomly shuffling tensors.

This version enqueues a different list of tensors in different threads.
It adds the following to the current `Graph`:

* A shuffling queue into which tensors from `tensor_list_list` are enqueued.
* A `dequeue_many` operation to create batches from the queue.
* A `QueueRunner` to `QUEUE_RUNNER` collection, to enqueue the tensors
  from `tensor_list_list`.

`len(tensor_list_list)` threads will be started, with thread `i` enqueuing
the tensors from `tensor_list_list[i]`. `tensor_list_list[i1][j]` must match
`tensor_list_list[i2][j]` in type and shape, except in the first dimension if
`enqueue_many` is true.

If `enqueue_many` is `False`, each `tensor_list_list[i]` is assumed
to represent a single example.  An input tensor with shape `[x, y,
z]` will be output as a tensor with shape `[batch_size, x, y, z]`.

If `enqueue_many` is `True`, `tensor_list_list[i]` is assumed to
represent a batch of examples, where the first dimension is indexed
by example, and all members of `tensor_list_list[i]` should have the
same size in the first dimension.  If an input tensor has shape `[*, x,
y, z]`, the output will have shape `[batch_size, x, y, z]`.

The `capacity` argument controls the how long the prefetching is allowed to
grow the queues.

##### Args: <a class="md-anchor" id="AUTOGENERATED-args-"></a>


*  <b>`tensor_list_list`</b>: A list of tuples of tensors to enqueue.
*  <b>`batch_size`</b>: An integer. The new batch size pulled from the queue.
*  <b>`capacity`</b>: An integer. The maximum number of elements in the queue.
*  <b>`min_after_dequeue`</b>: Minimum number elements in the queue after a
    dequeue, used to ensure a level of mixing of elements.
*  <b>`seed`</b>: Seed for the random shuffling within the queue.
*  <b>`enqueue_many`</b>: Whether each tensor in `tensor_list_list` is a single
    example.
*  <b>`shapes`</b>: (Optional) The shapes for each example.  Defaults to the
    inferred shapes for `tensor_list_list[i]`.
*  <b>`name`</b>: (Optional) A name for the operations.

##### Returns: <a class="md-anchor" id="AUTOGENERATED-returns-"></a>

  A list of tensors with the same number and types as `tensor_list_list[i]`.
